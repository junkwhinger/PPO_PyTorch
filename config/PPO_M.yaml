agent: PPO
device: cpu
env:
  nA: 4
  nS: 8
  name: LunarLander-v2
exp_name: PPO_M
experiment:
  clipping_gradient: false
  observation_normalization: false
  orthogonal_initialization_and_layer_scaling: false
  policy_noclip: false
  reward_clipping: false
  reward_standardization: false
  value_clipping: false
model:
  actor:
    betas:
    - 0.9
    - 0.999
    hidden_acivation_fn: tanh
    hidden_dims:
    - 64
    - 64
    lr: 0.002
  critic:
    betas:
    - 0.9
    - 0.999
    hidden_acivation_fn: tanh
    hidden_dims:
    - 64
    - 64
    lr: 0.002
seed: 77
train:
  average_interval: 100
  gae:
    tau: 0.95
  gail: false
  gamma: 0.99
  max_episodes: 5000
  max_steps_per_episode: 300
  ppo:
    batch_size: 32
    clip_range: 0.2
    coef_entpen: 0.001
    coef_vf: 0.5
    memory_size: 2048
    optim_epochs: 4
  terminal_score: 230
